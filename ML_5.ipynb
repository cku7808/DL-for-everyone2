{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOWTkcY2Fzh+VneCmGjf93A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cku7808/DL-for-everyone2/blob/main/ML_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax Classification "
      ],
      "metadata": {
        "id": "xLSAd1N380y9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞서 로지스틱 회귀에서 사용한 시그모이드 함수는 입력된 데이터에 대해서 0과 1사이의 값을 출력하여 2개의 선택지 중 1개를 고르는 이진 분류 문제를 해결했다.  \n",
        "소프트맥스 회귀는 3개 이상의 선택지 중 1개를 고르는 다중 클래스 분류 문제를 해결한다."
      ],
      "metadata": {
        "id": "J3lG9Tb3E9Ms"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2r5tJ2Wb8uyX"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "tf.enable_eager_execution()\n",
        "tf.set_random_seed(777)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data 준비"
      ],
      "metadata": {
        "id": "GtfJdr6j_yYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#feature가 4개인 8개의 데이터\n",
        "x_data = [[1,2,1,1],\n",
        "          [2,1,3,2],\n",
        "          [3,1,3,4],\n",
        "          [4,1,5,5],\n",
        "          [1,7,5,5],\n",
        "          [1,2,5,6],\n",
        "          [1,6,6,6],\n",
        "          [1,7,7,7]]\n",
        "          \n",
        "#class가 3개인 정답(라벨)데이터\n",
        "y_data = [[0,0,1],\n",
        "          [0,0,1],\n",
        "          [0,0,1],\n",
        "          [0,1,0],\n",
        "          [0,1,0],\n",
        "          [0,1,0],\n",
        "          [1,0,0],\n",
        "          [1,0,0]]\n",
        "\n",
        "#np.asarray : 원본 변경 시 복사본도 변경\n",
        "x_data = np.asarray(x_data, dtype=np.float32)\n",
        "y_data = np.asarray(y_data, dtype=np.float32)"
      ],
      "metadata": {
        "id": "tvXKXKaR_0s7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_classes = 3 #class 개수\n",
        "print(x_data.shape)\n",
        "print(y_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMS11m10A74r",
        "outputId": "b4619cd0-46df-4064-9332-877e43c9f24b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 4)\n",
            "(8, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#가중치와 바이어스 결정\n",
        "#tf.random.normal : 주어진 형태의 난수를 갖는 텐서 반환\n",
        "W = tf.Variable(tf.random_normal([4,nb_classes]), name=\"weight\")\n",
        "b = tf.Variable(tf.random_normal([nb_classes]), name=\"bias\")\n",
        "variables = [W,b]\n",
        "\n",
        "print(W,b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz-qo4TbBI3D",
        "outputId": "05cf617e-c238-4b1f-f692-663007b22be8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'weight:0' shape=(4, 3) dtype=float32, numpy=\n",
            "array([[ 0.7706481 ,  0.37335402, -0.05576323],\n",
            "       [ 0.00358377, -0.5898363 ,  1.5702795 ],\n",
            "       [ 0.2460895 , -0.09918973,  1.4418385 ],\n",
            "       [ 0.3200988 ,  0.526784  , -0.7703731 ]], dtype=float32)> <tf.Variable 'bias:0' shape=(3,) dtype=float32, numpy=array([-1.3080608 , -0.13253094,  0.5513761 ], dtype=float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "softmax 함수 사용"
      ],
      "metadata": {
        "id": "6cfg48hNGOeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#softmax 구현\n",
        "def hypothesis(X):\n",
        "  return tf.nn.softmax(tf.matmul(X, W)+b)\n",
        "\n",
        "print(hypothesis(x_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LumsUjzKDrOL",
        "outputId": "c8bc19ff-c5da-40d1-feb2-1e62deb8d889"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1.36571955e-02 7.90162291e-03 9.78441179e-01]\n",
            " [3.92597765e-02 1.70347411e-02 9.43705440e-01]\n",
            " [3.80385250e-01 1.67723149e-01 4.51891541e-01]\n",
            " [3.23390484e-01 5.90759404e-02 6.17533624e-01]\n",
            " [3.62997366e-06 6.20727221e-08 9.99996245e-01]\n",
            " [2.62520202e-02 1.07279625e-02 9.63019967e-01]\n",
            " [1.56525093e-05 4.21802724e-07 9.99983847e-01]\n",
            " [2.94076904e-06 3.81133241e-08 9.99996960e-01]], shape=(8, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_db = [[8,2,1,4]]\n",
        "sample_db = np.asarray(sample_db, dtype=np.float32)\n",
        "\n",
        "print(hypothesis(sample_db))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehUKIgnFFhKa",
        "outputId": "21e34c0f-e12d-45ba-e800-842737e304fd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.9302204  0.06200533 0.00777428]], shape=(1, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss function 정의(크로스 엔트로피)"
      ],
      "metadata": {
        "id": "r9sMnqrjGSWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$cost = - \\sum\\limits_{i}y_i log(\\hat{y}_i)$$"
      ],
      "metadata": {
        "id": "T1ME6WOoGWTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#손실함수 : 크로스엔트로피\n",
        "def cost_fn(X,Y):\n",
        "  logits = hypothesis(X)\n",
        "  cost = -tf.reduce_sum(Y*tf.log(logits), axis=1)\n",
        "  cost_mean = tf.reduce_mean(cost)\n",
        "\n",
        "  return cost_mean\n",
        "\n",
        "print(cost_fn(x_data,y_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMq1Jom6FyUR",
        "outputId": "c5482ed2-1538-449e-8eb6-0dd0b4dddc73"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(6.07932, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient descent 계산"
      ],
      "metadata": {
        "id": "-ZY3WmAZIwaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_fn(X,Y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = cost_fn(X,Y)\n",
        "    grads = tape.gradient(loss, variables)\n",
        "\n",
        "    return grads\n",
        "\n",
        "print(grad_fn(x_data, y_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-owAGfKIq16",
        "outputId": "3e194aee-4f67-49da-9e96-49eb501d3cde"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
            "array([[ 0.06914607, -0.6509784 ,  0.5818323 ],\n",
            "       [-1.5221257 , -1.214863  ,  2.7369885 ],\n",
            "       [-1.2473829 , -1.7611003 ,  3.0084827 ],\n",
            "       [-1.2014607 , -1.8659232 ,  3.0673835 ]], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.15212914, -0.342192  ,  0.49432108], dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 진행"
      ],
      "metadata": {
        "id": "VC_-v_aRJEes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(X,Y,epochs=2000, verbose=100):\n",
        "  optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "\n",
        "  for i in range(epochs):\n",
        "    grads = grad_fn(X,Y)\n",
        "    optimizer.apply_gradients(zip(grads, variables))\n",
        "    if(i==0) | ((i+1)%verbose==0):\n",
        "      print(\"Loss at epoch %d: %f\" %(i+1, cost_fn(X,Y).numpy()))\n",
        "\n",
        "fit(x_data, y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl2ubO8jJFp6",
        "outputId": "fee5d785-220e-49f5-ba73-ce13269d6519"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at epoch 1: 0.159427\n",
            "Loss at epoch 100: 0.154003\n",
            "Loss at epoch 200: 0.148872\n",
            "Loss at epoch 300: 0.144060\n",
            "Loss at epoch 400: 0.139539\n",
            "Loss at epoch 500: 0.135282\n",
            "Loss at epoch 600: 0.131269\n",
            "Loss at epoch 700: 0.127480\n",
            "Loss at epoch 800: 0.123896\n",
            "Loss at epoch 900: 0.120502\n",
            "Loss at epoch 1000: 0.117282\n",
            "Loss at epoch 1100: 0.114226\n",
            "Loss at epoch 1200: 0.111319\n",
            "Loss at epoch 1300: 0.108553\n",
            "Loss at epoch 1400: 0.105917\n",
            "Loss at epoch 1500: 0.103402\n",
            "Loss at epoch 1600: 0.101001\n",
            "Loss at epoch 1700: 0.098706\n",
            "Loss at epoch 1800: 0.096510\n",
            "Loss at epoch 1900: 0.094407\n",
            "Loss at epoch 2000: 0.092391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "prediction check"
      ],
      "metadata": {
        "id": "-rpt6cpGlxxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = hypothesis(x_data)\n",
        "print(a)\n",
        "print(tf.argmax(a,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPl_AVTVlv7z",
        "outputId": "ed8dd636-1d2c-424b-c8ad-223a8e5380b7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[2.9436805e-08 1.5021235e-04 9.9984980e-01]\n",
            " [4.3665289e-04 4.6358626e-02 9.5320481e-01]\n",
            " [9.5460018e-10 9.6164070e-02 9.0383589e-01]\n",
            " [2.2774371e-07 9.1306245e-01 8.6937323e-02]\n",
            " [1.6050829e-01 8.3273548e-01 6.7562237e-03]\n",
            " [8.4970415e-02 9.1502690e-01 2.6765201e-06]\n",
            " [8.2284725e-01 1.7714940e-01 3.2996732e-06]\n",
            " [9.6834594e-01 3.1654030e-02 1.4558012e-08]], shape=(8, 3), dtype=float32)\n",
            "tf.Tensor([2 2 2 1 1 1 0 0], shape=(8,), dtype=int64)\n"
          ]
        }
      ]
    }
  ]
}